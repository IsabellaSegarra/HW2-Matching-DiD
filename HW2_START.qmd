---
title: "ðŸŒ¬ï¸ðŸ—³ Assignment 2: Wind Turbines, Matching, and Difference-in-Differences"
subtitle: "Replicate causal inference identification strategies in Stokes (2015) "
author: "EDS 241 / ESM 244 (DUE: 2/4/26)"
format:
  html:
    theme: sketchy
    css: styles.css
date: "January 26, 2026"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

### Assignment instructions

Working with classmates to troubleshoot code and concepts is encouraged. If you collaborate, list collaborators at the top of your submission.

All written responses must be written independently (in your own words).

Keep your work readable: Use clear headings and label plot elements thoughtfully.

Assignment submission (YOUR NAME): Isabella Segarra

------------------------------------------------------------------------

### Introduction 

In this assignment you will be doing political weather forecasting except the â€œstormsâ€ we care about are electoral swings that might follow local wind turbine development.

In Stokes (2015), the idea is that a policy with diffuse benefits (cleaner electricity) can create concentrated local costs (turbines nearby), and those local opponents may â€œsend a signalâ€ at the ballot box (i.e., NIMBYISM). Your job is to use two statistical tools:

- Matching: Can we create a more apples-to-apples comparison between precincts that did vs. did not end up near turbine proposals?
- Fixed effects + Difference-in-Differences: Can we use repeated elections to estimate how within-precinct changes in turbine exposure relate to changes in incumbent vote share?

------------------------------------------------------------------------

### Learning goal: Replicate the matching and fixed effects analyses from study:

> Stokes (2015): *"Electoral Backlash against Climate Policy: A Natural Experiment on Retrospective Voting and Local Resistance to Public Policy*. 

- **Study:** [Stokes (2015) - Article](https://drive.google.com/file/d/1y2Okzjq2EA43AW5JzCvFS8ecLpeP6NKh/view?usp=sharing)
- **Data source:** [Dataverse-Stokes2015](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/SDUGCC)

::: callout
`NOTE:` Replication of study estimates will be approximate. An alternative matching procedure and fixed effects estimation package are utilized in this assignment for illustration purposes. 
:::

------------------------------------------------------------------------

### Setup: Load libraries 

0. Load libraries (+ install if needed)

```{r}

library(tidyverse)
library(here)
library(janitor)
library(jtools)

library(gtsummary)
library(gt)

library(MatchIt) # matching
library(cobalt)  # balance + love plots

library(fixest) # fast fixed effects
library(scales) # plotting

```

------------------------------------------------------------------------

### Part 1: Study Background 

#### **1A.** Dive into the details of the study design and evaluation plan

> Goal: Get familiar with the study setting, environmental issue, and policy under evaluation.

::: callout
`NOTE:` Read over study to inform your response to the assignment questions. For this assignment we will skip-over sections that describe the *Instrumental Variables* identification strategy. We will cover instrumental variable designs weeks 6-7.
:::

**1A.Q1** Summarize the environmental policy issue, the outcome of interest, and the intervention being evaluated. 
Be sure to include a brief description of each of the following key elements of the study: unit of analysis, outcome, treatment, comparison group): 

*Response:*The environmental policy issue in this study is climate change mitigation with wind-turbine renewable energy, focusing on building renewable energy for Ontario's electricity system with a feed-in tariff program. Although many people of Ontario support wind energy, there are local organizations organized to fight the proposed turbines. This study investigated whether people of Ontario living in proximity to wind energy punished the incumbent government because of its climate policy. The author used a fixed effects model with a unit of analysis being voting precinct (around 350 voters) and treatment of proposed or operational turbine within precinct boundaries vs. similar precincts that did not receive turbines. The outcome variable is Liberal Party vote share at the precinct level.

**1A.Q2** Why might turbine proposals be correlated with baseline political preferences or rural areas? Provide 2 plausible mechanisms, and explain why that creates confounding.

*Response:* The placement of wind turbines can be associated with more Liberal politics and be more associated with more urban regions. However, because rural areas have more access to land and therefore, can implement more wind turbines, this can confound the causal relationship of political preference and renewable energy. Additionally, turbine developers may place turbines in regions with more lenient policies and lack of community-involvement/democratization of choices, making it more likeley that rural areas, with more conservative political preferences, are given more wind turbines. 

------------------------------------------------------------------------

#### **1B.** Break down the causal inference strategy and identify threats to identification:

**1B.Q1**  What is the key identifying assumption for a fixed effects / Difference-in-Difference design? Explain how this assumption when satisfied provides evidence of causal effect: 

*Response:*  In a fixed effects + DiD framework, the main assumption of the methods include parallel trends. This states that in the absence of  treatment, the treated and control units would have followed the same trend across time. 

**1B.Q2**  What is the reason for using a fixed effects approach from a causal inference perspective? Summarize within the context of study (in your own words).

*Response:* Fixed effect models ensure that you are only comparing differences within groups. In the context of this study, some precincts with turbines might differ from precints without turbines -- temporally and characteristically -- this influences the Liberal vote.

**1B.Q3** What part of the SUTVA assumption is most likely violated in the context of this study design (and why)?

*Response:* Although treatment is consistent between the precints, the proximity to other wind turbines influences those in well,defined no-turbine precincts. For instance, people can hear the wind turbines and that can influence the Liberal vote. 


**1B.Q4**  Why does spillover matter when estimating an unbiased treatment effect? 

*Response:* Spillover is important because this influences the coefficients for treatment effect, reducing its impact on the observed and contaminating the control. 

**1B.Q5** How do the authors assess the risk of spillovers, and what analytic choice do they make to attempt to mitigate the risk that spillover biases the causal estimate?

*Response:* In order to assess the risk of spillovers, especially considering the affect of turbines on neighboring precincts, the authors redefined treatment in terms of distance to turbines. Spillover refers to the effect of wind turbines extending beyond the precincts where turbines are physically located to neighboring precincts. 


------------------------------------------------------------------------

### Part 2: Matching 

------------------------------------------------------------------------

We will start by evaluating the 2007 survey (cross-sectional) data. Treatment is defined by whether a precinct is near a turbine proposal (within 3 km). 

> Goal: Match precincts using pre-treatment covariates and then estimate the effect of proposed wind turbines on incumbent vote share.

#### **2A.** Load data for matching

1. Read in data file `stokes15_survey2007.csv`
2. Code `precinct_id` and `district_id` as factors
3. Take a look at the data

```{r}

match_data <- read_csv(here("data", "stokes15_survey2007.csv")) %>% 
    janitor::clean_names() %>% # lower snack case 
    mutate(
        precinct_id = as.factor(precinct_id),
        district_id = as.factor(district_id)
    )
    
```


**2A.Q1** Intuition check: **Why match?** Explain rationale for using this method. 

*Response:* This dataset is ideal for matching because it has many covariates and control observations. In this way, you can take each treated unit and look across another group for the closest match. Matching is a method to compare the average treatment effect by finding two matching pairs, with similar attributes, but the only difference is the treatment effect. This is a method to reduce selection bias. 

------------------------------------------------------------------------

#### **2B.** Check imbalance (before matching)

- Create a covariate *balance table* comparing treated and control precincts 
- Treatment indicator: `proposed_turbine_3km`
- Include pre-treatment covariates: `log_home_val_07`, `p_uni_degree`, `log_median_inc`, `log_pop_denc` 
- Use the `tbl_summary()` function from the `{gtsummary}` package.

```{r}

match_data %>%
    select(proposed_turbine_3km, log_home_val_07, p_uni_degree, log_median_inc, log_pop_denc) %>% 
    tbl_summary(
        by = proposed_turbine_3km, 
        statistic = list(all_continuous() ~ "{mean} ({sd})"),
        label = list(
            log_home_val_07 ~ "Log Home Value (2007)",
            p_uni_degree ~ "% University Degree",
            log_median_inc ~ "Log Median Income",
            log_pop_denc ~ "Log Population Density"
        )
    ) %>%
    modify_header(label ~ "**Covariate**") %>%
    modify_spanning_header(c("stat_1", "stat_2") ~ "**Treatment Status**") %>%
    add_p() 
    
    
```


**2B.Q1** Summarize the table output: Which covariates look balanced/imbalanced?

*Response:* Log population density and % University degree shows the most difference between control and treatment. 

**2B.Q2** Describe in your own words why these covariates might be expected to confound the treatment estimate: 

*Response (2-4 sentences):* These variables can influence the treatment because larger precincts are associated with more urban regions and therefore, more Liberal preferences. In addition, university degrees are also associated with more Liberal preferences. 

------------------------------------------------------------------------

**2B.Q3** Intuition check: What type of data do you need to conduct a matching analysis? 

*Response:* In order to conduct a matching analysis, you need to use panel data with many covariates and observations. 

------------------------------------------------------------------------

### Conduct matching estimation using the {`MatchIt`} package:

ðŸ“œ [Documentation - MatchIt](https://kosukeimai.github.io/MatchIt/)

Learning goals: 

- Approximate the Mahalanobis matching method used in Stokes (2015)
- Implement another common matching approach called `propensity score matching`

::: callout
`NOTE`: In the replication code associated with Stokes (2015) the {`AER`} package is used for Mahalanobis matching. In this assignment we use the {`MatchIt`} package. The results are comparable but will not be exactly the same. 
:::

------------------------------------------------------------------------

### 2C. Mahalanobis nearest-neighbor matching 

- Conduct Mahalanobis matching  
- Use nearest-neighbor match without replacement using Mahalanobis distance
- Use 1-to-1 matching (match one control unit to each treatment unit)
- Extract the matched data using `match.data()`

```{r}
set.seed(2412026)

match_model <- matchit(proposed_turbine_3km ~ log_home_val_07 + p_uni_degree + 
                           log_median_inc + log_pop_denc,
     # Treatment_indicator ~  Pre_treatment_covariates
  data = match_data, 
  method = "nearest",       # Nearest neighbor matching
  distance = "mahalanobis", # Mahalanobis distance
  ratio = 1,                # Match one control unit to one treatment unit (1:1 matching)
  replace = FALSE           # Control observations are not replaced
)

# Extract matched data
matched_data <- match.data(match_model)

```

```{r}
summary(match_model)
```

**2C.Q1** Using the `summary()` output: Which covariate had the largest and smallest `Std. Mean Diff.` before matching. Next, compare largest/smallest `Std. Mean Diff.` after matching. 

*Response:* The covariate with the largest `Std. Mean Diff.` or SMD before and after matching was log population density. The covariate with the smallest is log median income. 


------------------------------------------------------------------------

#### 2D. Create a "love plot" using `love.plot()` â¤ï¸

ðŸ“œ [Documentation - cobalt](https://ngreifer.github.io/cobalt/)

- Plot mean differences for data before & after matching across all pre-treatment covariates
- This is an effective way to evaluate how effective matching was at achieving balance.

-----------------------------------------------------------------------

- Make a love plot of standardized mean differences (SMDs) before vs after matching.
- Include a threshold line at 0.1. 
- In love plot display `mean.diffs`  

```{r}

new_names <- data.frame(
    old = c("log_home_val_07", "p_uni_degree", "log_median_inc", "log_pop_denc"),
    new = c("Home Value (log)", "Percent University Degree",
            "Median Income (log)", "Population Density (log)"))

# Love plot
love.plot(match_model, stats = "mean.diffs",
          thresholds = c(m = 0.1),
          var.names = new_names)

```

**2D.Q1** Interpret the love plot in your own words:

*Response:*The purpose of a love plot is to assess which variables are potentially problematic in this analysis because they have a large SMD. The love plot shows that population density and percent university degree show a large SMD. A love plot helps us compare the SMD between the unadjusted and adjusted samples. 

------------------------------------------------------------------------

### Propensity score matching 

------------------------------------------------------------------------

#### 2E. Propensity Score Matching (PSM) 

 - Estimate 1:1 nearest-neighbor Propensity Score Matching 
 - Same code as above except change `distance = "logit"`  
 
```{r}

set.seed(2412026)

propensity_scores <- matchit(proposed_turbine_3km ~ log_home_val_07 + p_uni_degree + 
                           log_median_inc + log_pop_denc,
     # Treatment_indicator ~  Pre_treatment_covariates
  data = match_data, 
  method = "nearest",       # Nearest neighbor matching
  distance = "logit", # Logit distance
  ratio = 1,                # Match one control unit to one treatment unit (1:1 matching)
  replace = FALSE           # Control observations are not replaced
)

# Extract propensity data
propensity_data <- match.data(propensity_scores)
    
```

------------------------------------------------------------------------

#### Create table displaying covariate balance using `cobalt::bal.tab()`

ðŸ“œ [Documentation - cobalt](https://ngreifer.github.io/cobalt/)

Use `bal.tab()` to report balance before and after matching.

```{r}

bal.tab(propensity_scores, 
        var.names = new_names) 

```

**2E.Q1** Compare Mahalanobis vs propensity score matching. Which method did a better job at achieving balance?

*Response:* The Mahalanobis method had overall better SMD values than propensity score matching, signifying a better balance. 3 out of 4 covariates have smaller SMD with Mahalanobis. There are larger imbalances with propnesity scores. 


------------------------------------------------------------------------

#### 2F. Estimate an effect in the matched sample

Using the matched data (Mahalanobis method), estimate the effect of treatment on the change in incumbent vote share (`change_liberal`).

```{r}

reg_match <- lm(change_liberal ~ proposed_turbine_3km,
  data = matched_data
)

summ(reg_match, model.fit = FALSE)
```

**2F.Q1** Have you identified a causal estimate using this approach: Why or why not? 

*Response:* This approach returned significant p values, however it is not enough to determine a causal estimate because other covariates are excluded from the data. 

Balances observable covariates between treated and control groups
Removes confounding from measured variables (home value, education, income, density)
Makes treated and control precincts more comparable

**2F.Q2** When using a matching method, what is the main threat to causal identification?

*Response:* The main threat to causal identification is omitted variables. Although matching balances observable covariates, the covariates not included in the matching or within the data can confound actual causual relationships. 

**2F.Q3** Describe why the treatment estimate represents the `Average Treatment for the Treated (ATT)` and explain why this is the case relative to estimation of the `Average Treatment Effect (ATE)`.

*Response:* The treatment estimate represents the ATT because it only calculates the estimate based on precints that recieved the treatment (within 3km of wind turbines). THis is because the model looks at the predicts the `change_liberal` variable based on the `proposed_turbine_3km` which are only the precincts within the treatmon zone. As opposed to ATE, this is if we randomly assigned the treatment to all the precincts, regardless of turbine proposal or not. 


------------------------------------------------------------------------

### Part 3: Panel Data, Fixed Effects, and Difference-in-Difference

**Data source:** [Dataverse-Stokes2015](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/SDUGCC)

------------------------------------------------------------------------

#### **3A:** Read in the panel data + code variables `precinct_id` and `year` as factors 

```{r}

panel_data <- read_csv(here("data", "Stokes15_panel_data.csv"))

tabyl(panel_data$year)

# HINT: Try running `tabyl(panel_data$year)`. Review article to make sense of the row numbers (n).

```

**3A.Q1:** Why are there 18,558 rows in `panel_data`?

*Response:* There are 18,558 rows of data because each row corresponds to three years -- 2003, 2007, and 2011-- corresponding to election years and years before the Green Act (2003) and years of intervention (2007-2011). 

```{r}
# How many years are included in the panel?
length(unique(panel_data$year))

# How many precincts are there?
length(unique(panel_data$precinct_id))

# How many precints are proposed and opoerational

# How many unique precincts were treated?
propopsed_precints <- panel_data %>% 
    filter(proposed_turbine == 1) %>% 
    summarise(n_unique_precincts = n_distinct(precinct_id))
propopsed_precints # 184 

operational_precints <- panel_data %>% 
    filter(operational_turbine == 1) %>% 
    summarise(n_unique_precincts = n_distinct(precinct_id))
operational_precints # 52

```

**3A.Q2:** How many unique precincts are *ever treated* (i.e., `proposed` & `operational`)?

*Response:* The amount of unique precints treated were 236. 

```{r}

panel_data %>%
  group_by(precinct_id) %>%
  summarise(
    ever_proposed    = any(proposed_turbine == 1, na.rm = TRUE),
    ever_operational = any(operational_turbine == 1, na.rm = TRUE),
    .groups = "drop") %>%
  summarise(
    n_ever_proposed    = sum(ever_proposed),
    n_ever_operational = sum(ever_operational))

```

------------------------------------------------------------------------

#### **3B.** Plot and evaluate parallel trends: Replicate `Figure.2` (Stokes, 2015)

1. Create indicators for whether each precinct is ever treated by 2011 (`treat_p`, `treat_o`; separate indicator for proposals and operational turbines).
2. Plot mean incumbent vote share by year for treated vs control precincts (with 95% CIs). 
3. Facet by turbine type (proposed & operational)

Step 1: Prepare data 
```{r}

trends_data <- panel_data %>%
  group_by(precinct_id) %>%
  mutate(
    treat_p = as.integer(any(proposed_turbine == 1, na.rm = TRUE)),  # ever proposed (in any year)
    treat_o = as.integer(any(operational_turbine == 1, na.rm = TRUE))) %>% # ever operational (in any year)
  ungroup() %>% 
  pivot_longer(c(treat_p, treat_o),
               names_to = "turbine_type", values_to = "treat") %>% 
  mutate(
      turbine_type = factor(turbine_type,
                            levels = c("treat_p", "treat_o"),
                            labels = c("Proposed turbines", "Operational turbines")),  
    status = if_else(treat == 1, "Treated", "Control"),
    year   = factor(year))

```

Step 2: Create trends plot 
```{r}

pd <- position_dodge(width = 0.15)

trends_data %>%
  group_by(turbine_type, status, year) %>%
  summarise(
    mean = mean(perc_lib, na.rm = TRUE),
    n    = sum(!is.na(perc_lib)),
    se   = sd(perc_lib, na.rm = TRUE) / sqrt(n), 
    ci   = qt(.975, df = pmax(n - 1, 1)) * se,
    .groups = "drop") %>%
ggplot(aes(year, mean, color = status, group = status)) +
  geom_line(position = pd, linewidth = 1.2) +
  geom_point(position = pd, size = 2.6) +
  geom_errorbar(
    aes(ymin = mean - ci, ymax = mean + ci),
    position = pd, width = .12, linewidth = .7, color = "black") +
  facet_wrap(~ turbine_type, nrow = 1) +
  scale_color_manual(values = c(Control = "#0072B2", Treated = "#B22222")) +
  scale_y_continuous(labels = percent_format(accuracy = 1)) +
  coord_cartesian(ylim = c(.20, .57)) +
  labs(
    title = "Figure 2. Trends in the Governing Partyâ€™s Vote Share",
    x = "Election Year",
    y = "Liberal Party Vote Share",
    color = NULL) +
  theme_minimal(base_size = 14) +
  theme(
    panel.grid.minor = element_blank(),
    legend.position = "bottom",
    strip.text = element_text(face = "bold"))

```

**3B.Q1:** Write a short paragraph assessing the parallel trends assumption for each outcome.

*Response (4-6 sentences):* For the **proposed turbines**, the pre-treatment years between 2003 and 2007 display parallel trends, with most groups sharing a ~45% Liberal vote share. In 2007, after intervention, the data displays that the treated precints declined in their Liberal vote share, an obvious sign of the treatment effect. For the **operational turbines**, the treatment and control groups display parallel trends, however the treated precincts have a higher liberal vote share baseline than the control group, displaying less of an apples-to-apples comparison. After the treatment in 2007, treated Liberal vote declined, but so did the control group. This can also be due to the smaller sample of operaitonal turbines (52). 



------------------------------------------------------------------------

### Estimating Fixed Effects Models (DiD) for proposals

$$
\text{Y}_{it}
=  \alpha_0 +
\beta \cdot (\text{proposed_turbine}_{it})
+ \gamma_i
+ \delta_t
+ \varepsilon_{it}
$$

- $Y_{it}$ is the vote share for the Liberal Party in precinct *i* in time *t*
- $\beta$ is the treatment effect of a turbine being proposed within a precinct
- $\gamma_i$ is the precinct fixed effect
- $\delta_t$ is the year fixed effect

------------------------------------------------------------------------

### Example 1: Randomly sample 40 precincts

- To illustrate the "dummy variable method" of estimating fixed effects using the the general `lm()` function we are going to randomly sample 40 precincts (20 "treated" precincts with proposed turbines). 
- If we attempted to use this approach with the full sample estimating all 6185 (n-1) precinct-level coefficients is impractical (it would take a long time).

```{r}
set.seed(40002026)

precinct_frame <- panel_data %>%
  group_by(precinct_id) %>%
  summarise(
    proposed_turbine_any = as.integer(any(proposed_turbine == 1, na.rm = TRUE)),
    .groups = "drop"
  )

ids_40 <- precinct_frame %>%
  group_by(proposed_turbine_any) %>%
  slice_sample(n = 20) %>%
  ungroup() %>%
  select(precinct_id)

sample_40_precincts <- panel_data %>%
  semi_join(ids_40, by = "precinct_id")

```

------------------------------------------------------------------------

#### **3C:** Estimate a fixed effects model using `lm()` with fixed effects added for `precinct` and `year` using the sample of 40 precincts just created.

```{r}
model1_ff <- lm(perc_lib ~ proposed_turbine + precinct_id + year, data = sample_40_precincts)

summ(model1_ff , model.fit = FALSE, digits = 3)
```

```{r}
summ(model1_ff, model.fit = FALSE, robust = TRUE)
```

**3C.Q1:** Intuition check: Is the *signal-to-noise* ratio for the treatment estimate greater than *2-to-1*?

*Response:* The signal to noise ratio for the treatment effect is less than 2 to 1.  

> HINT: Add the argument `digits = 3` to the `summ()` function above

**3C.Q2:** Re-run the `summ()` function using the *heteroscedasticiy robust standard error adjustment* (`robust = TRUE`). Did the standard error (S.E.) estimates change? Explain why. 

*Response:* Without the robust=TRUE argument, the SE is 0.031 and with the argument, the SE is 0.04. This changes the standard error because outliers in the dataset are not changing the averages. The argument allows the standard error to not assume constant variance (homoskedasticity). 

**3C.Q3:** Compare results of the model above to the findings from the fixed effects analysis in the Stokes (2015) study. Why might the results be similar or different? 

*Response:* The results for this model are slightly different from those in Stokes (2015) and the p-values for this model show less significance than the original study. This can be due to this model being ran on a sample of the data. 

**3C.Q4:** In your own words, explain why it is advantageous from a causal inference perspective to include year and precinct fixed effects. Explain how between-level and within-level variance is relevant to the problem of omitted variable bias (OVB). 

*Response (2-4 sentences):* It is important to include year as a fixed effect because year directly relates to election years, policy changes, governance changes, etc. The inclusion of precinct is important because there is natural variation across precincts that can influence the liberal vote. Including between-level or variations across precints and within-level or changes within precincts across time is important because it can help control for other omitted variables not included, such as policy change or precinct voting. 

------------------------------------------------------------------------

#### **3D.** Now using the full sample, estimate the treatment effect of wind turbine proposals on incumbent vote share. Use `feols()` from the `{fixest}` package to estimate the fixed effects.

See vignette here: [fixest walkthrough](https://cran.r-project.org/web/packages/fixest/vignettes/fixest_walkthrough.html#11_Estimation)

```{r}

model2_ff <- feols(
    perc_lib ~ proposed_turbine | year + precinct_id, # Add fixed effects 
    data = panel_data, 
    cluster = ~precinct_id # cluster by precinct_id 
)
summary(model2_ff, cluster = ~precinct_id)
```

**3D.Q1:** Interpret the model results and translate findings to be clear to an audience that may not have a background in causal inference (Econometrics) methods.

In panel data settings, why is clustering by precinct important (i.e., `cluster = ~precinct_id`) ?â€

*Response (4-6 sentences):* This model examines the relationship between proposed wind turbines and Liberal Party vote share in Ontario precincts. It includes fixed effects for year and precinct ID to control for variation within precincts over time and common trends across all precincts in each election year. The model predicts that proposed wind turbines lead to a 4.2 percentage point decline in Liberal vote share,compared to similar precincts without proposed turbines, with a highly significant p-value (p < 0.001), indicating this relationship is extremely unlikely to be due to chance. For example, in a precinct with an average Liberal vote share of 36%, the presence of a proposed turbine is associated with a decline to approximately 32%. Clustering by precinct id is important because it accounts for the natural variation across precincts. 

------------------------------------------------------------------------

#### **3E.** Estimate the treatment effect of *operational wind turbines* on incumbent vote share. Use the same approach as the previous model.

```{r}

model3_ff <-  feols(
    perc_lib ~ operational_turbine | year + precinct_id, # Add fixed effects 
    data = panel_data, 
    cluster = ~precinct_id # cluster by precinct_id 
)
    
summary(model3_ff, model.fit = FALSE)
```


**3E.Q1:** Interpret the `model3_ff` results as clearly and **concisely** as you can.

*Response:* The results show that operational wind turbines lead to a 9.3 percentage point decline in Liberal vote share compared to similar precincts without operational turbines, with an extraordinarily significant p-value (p < 0.001).  

**3E.Q2:** Why do you think the effect of proposed wind turbines is different from operational wind turbines. Develop your own theory about why incumbent vote share is affected in this way. Use the Stokes (2015) study to inform your response as needed. 

*Response:* The effect of proposed wind turbines has a greater effect (9% decline in liberal vote) versus operational wind turbines (7% decline) because when policy are being implemented, many people are interested in involved in hearing about the policies, especially around election times. For precincts will operational turbines, many are unaware about its impacts and do not consider those when voting. 



------------------------------------------------------------------------

```{r, message=TRUE, echo=FALSE, eval=FALSE}

library(praise); library(cowsay)

praise("${EXCLAMATION}! ðŸš€ Great work - You are ${adjective}! ðŸ’«")

say("The End", "duck")
```



